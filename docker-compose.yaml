version: '2.4'
networks:
  cassandra:
services:
  zoo:
    image: zookeeper:3.4.9
    container_name: zoo
    ports:
      - "2181:2181"
    environment:
        ZOO_MY_ID: 1
        ZOO_PORT: 2181
        ZOO_SERVERS: server.1=zoo:2888:3888
    volumes:
      - zoo:/data
      - zoolog:/datalog

  kafka1:
    image: confluentinc/cp-kafka:5.3.1
    container_name: kafka1
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zoo:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka1:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    command: sh -c "((sleep 10 && kafka-topics --create --if-not-exists --zookeeper zoo:2181 --replication-factor 3 --partitions 3 --config --topic game-moves)&) && /etc/confluent/docker/run "
    volumes:
      - kafka1:/var/lib/kafka/data
    depends_on:
      - zoo
    healthcheck:
      test: nc -z localhost 9092
      interval: 10s
      timeout: 30s
      retries: 2

  kafka2:
    image: confluentinc/cp-kafka:5.3.1
    container_name: kafka2
    ports:
      - "9093:9093"
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: zoo:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka2:9093,PLAINTEXT_HOST://localhost:29093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    command: sh -c "((sleep 10 && kafka-topics --create --if-not-exists --zookeeper zoo:2181 --replication-factor 3 --partitions 3 --config --topic game-events)&) && /etc/confluent/docker/run "
    volumes:
      - kafka2:/var/lib/kafka/data
    depends_on:
      - zoo
    healthcheck:
      test: nc -z localhost 9093
      interval: 10s
      timeout: 30s
      retries: 2

  kafka3:
    image: confluentinc/cp-kafka:5.3.1
    container_name: kafka3
    ports:
      - "9094:9094"
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: zoo:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka3:9094,PLAINTEXT_HOST://localhost:29094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    volumes:
      - kafka3:/var/lib/kafka/data
    depends_on:
      - zoo
    healthcheck:
      test: nc -z localhost 9094
      interval: 10s
      timeout: 30s
      retries: 2

#
#  cass1:
#    build: . # better to use a specific version, if you want to control upgrades
#    container_name: cass1
#    hostname: cass1
#    mem_limit: 3g  # It's not strictly required, but it's better to have some memory limit
#    healthcheck:
#        test: ["CMD", "cqlsh", "-e", "describe keyspaces" ]
#        interval: 5s
#        timeout: 5s
#        retries: 60
#    networks:
#      - cassandra
#    ports:
#      - "9042:9042"  # Expose native binary CQL port for your apps
#    volumes:
#      - ~/data/cass1:/var/lib/cassandra    # This is the volume that will persist data for cass1 node
#    environment: &environment    # Declare and save environments variables into "environment"
#        CASSANDRA_SEEDS: "cass1,cass2"    # The first two nodes will be seeds
#        CASSANDRA_CLUSTER_NAME: SolarSystem
#        CASSANDRA_DC: Mars
#        CASSANDRA_RACK: West
#        CASSANDRA_ENDPOINT_SNITCH: GossipingPropertyFileSnitch
#        CASSANDRA_NUM_TOKENS: 128
#        CASSANDRA_KEYSPACE: test

#  cass2:
#    image: cassandra:3.11.8
#    container_name: cass2
#    hostname: cass2
#    healthcheck:
#        test: ["CMD", "cqlsh", "-e", "describe keyspaces" ]
#        interval: 5s
#        timeout: 5s
#        retries: 60
#    networks:
#      - cassandra
#    ports:
#      - "9043:9042"  # Expose native binary CQL port for your apps
#    volumes:
#      - ./data/cass2:/var/lib/cassandra    # This is the volume that will persist data for cass2 node
#    environment: *environment    # point to "environment" to use the same environment variables as cass1
#    depends_on:
#      cass1:    # start cass2 only after cass1 is healthy
#        condition: service_healthy
#
#  cass3:
#     image: cassandra:3.11.8
#     container_name: cass3
#     hostname: cass3
#     healthcheck:
#         test: ["CMD", "cqlsh", "-e", "describe keyspaces" ]
#         interval: 5s
#         timeout: 5s
#         retries: 60
#     networks:
#       - cassandra
#     ports:
#       - "9044:9042"  # Expose native binary CQL port for your apps
#     volumes:
#       - ./data/cass3:/var/lib/cassandra    # This is the volume that will persist data for cass3 node
#     environment: *environment    # point to "environment" to use the same environment variables as cass1
#     depends_on:
#       cass2:    # start cass3 only after cass1 is healthy
#         condition: service_healthy # cass3 only after cass2
#  kafka-sr1:
#   image: 'confluentinc/cp-schema-registry:latest'
#   container_name: 'kafka-sr1'
#   hostname: 'kafka-sr1'
#   healthcheck:
#     test: ["CMD-SHELL", "nc -z kafka-sr1 8081 || exit 1" ]
#     interval: 5s
#     timeout: 5s
#     retries: 60
#   networks:
#     - kafka-net
#   ports:
#     - '8081:8081'
#   environment:
#     - SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS=kafka1:9092
#     - SCHEMA_REGISTRY_HOST_NAME=kafka-sr1
#     - SCHEMA_REGISTRY_LISTENERS=http://kafka-sr1:8081
#   depends_on:
#     - zoo


#  kafka-connect1:
#    image: 'confluentinc/cp-kafka-connect:latest'
#    container_name: 'kafka-connect1'
#    hostname: 'kafka-connect1'
#    healthcheck:
#      test: [ "CMD-SHELL", "nc -z localhost 8082 || exit 1" ]
#      interval: 5s
#      timeout: 5s
#      retries: 60
#    networks:
#      - kafka-net
#    ports:
#      - '8082:8082'
#    volumes:
#      - ./vol-kafka-connect-jar:/etc/kafka-connect/jars
#      - ./vol-kafka-connect-conf:/etc/kafka-connect/connectors
#    environment:
#      - CONNECT_BOOTSTRAP_SERVERS=kafka1:9092
#      - CONNECT_REST_PORT=8082
#      - CONNECT_GROUP_ID=cassandraConnect
#      - CONNECT_CONFIG_STORAGE_TOPIC=cassandraconnect-config
#      - CONNECT_OFFSET_STORAGE_TOPIC=cassandraconnect-offset
#      - CONNECT_STATUS_STORAGE_TOPIC=cassandraconnect-status
#      - CONNECT_KEY_CONVERTER=org.apache.kafka.connect.json.JsonConverter
#      - CONNECT_VALUE_CONVERTER=org.apache.kafka.connect.json.JsonConverter
#      - CONNECT_INTERNAL_KEY_CONVERTER=org.apache.kafka.connect.json.JsonConverter
#      - CONNECT_INTERNAL_VALUE_CONVERTER=org.apache.kafka.connect.json.JsonConverter
#      - CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE=false
#      - CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE=false
#      - CONNECT_REST_ADVERTISED_HOST_NAME=kafka-connect
#      - CONNECT_PLUGIN_PATH=/etc/kafka-connect/jars
#      - CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR=1
#      - CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR=1
#      - CONNECT_STATUS_STORAGE_REPLICATION_FACTOR=1
#    depends_on:
#      zoo:
#        condition: service_started
#      kafka1:
#          condition: service_healthy


  producer:
     build: ./producer/.
     container_name: producer
     environment:
       KAFKA: "kafka1:9092"
     depends_on:
       kafka1:
         condition: service_healthy

  consumer:
     build: ./consumer/.
     container_name: consumer
     environment:
       KAFKA1: "kafka1:9092"
       KAFKA2: "kafka2:9093"
       KAFKA3: "kafka3:9094"
     depends_on:
      kafka1:
         condition: service_healthy
      kafka2:
         condition: service_healthy
      kafka3:
         condition: service_healthy



volumes:
  zoo:
  zoolog:
  kafka1:
  kafka2:
  kafka3: